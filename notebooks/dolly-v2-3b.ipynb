{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/adammuhtar/llm-notebooks/blob/main/notebooks/dolly-v2-3b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG3E1B_zrYxy"
      },
      "source": [
        "# **Dolly 2.0 üêëüß±: An Open-Source Instruction-Tuned Large Language Model**\n",
        "\n",
        "The development of large language models (LLMs) have been nothing short of remarkable, revolutionising the field of natural language processing (NLP) and potentially moving humanity slightly closer towards building an artificial general intelligence. With the advent of large pre-trained models such as GPT-3 and GPT-4, these models are becoming increasingly sophisticated, with the latest models leveraging on billions of parameters and demonstrating impressive language processing capabilities. Equally as exciting is the growing trend towards making these models more accessible to researchers and developers alike, with many pre-trained models becoming freely available.\n",
        "\n",
        "[**Dolly 2.0**](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)\n",
        "\n",
        "On 12 April 2023, [Databricks](https://www.databricks.com) introduced the Dolly 2.0 language model, which is the first true open-source viable language model. There are two key components sets this model apart:\n",
        "1. It is trained on ~15k instruction/response fine tuning records (available here: [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)) generated by Databricks employees in capability domains from the InstructGPT paper, including brainstorming, classification, closed QA, open QA, generation, information extraction, and summarisation. The fact that [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data) was sourced from over 5,000 Databricks employees will likely incorporate diversity into the dataset itself.\n",
        "2. The model is not trained using the [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) models, but using open-sourced alternatives - in this case, EleutherAI's Pythia models. While Pythia is not as 'deep' as [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) (trained on 300 billion tokens as opposed to 1 trillion tokens), the use of Pythia could potentially open up LLM use-cases beyond research.\n",
        "\n",
        "This notebook explores how to replicate and run the Dolly 2.0 for causal language modelling.\n",
        "\n",
        "[**Pythia**](https://huggingface.co/EleutherAI/pythia-6.9b)\n",
        "\n",
        "Pythia is a suite of decoder-only autoregressive language models ranging from 70M to 12B parameters developed by [EleutherAI](https://www.eleuther.ai). It combines interpretability analysis and scaling laws to understand how knowledge develops and evolves during training in autoregressive transformers. Pythia is designed to enable controlled scientific research on openly accessible and transparently trained LLMs.\n",
        "\n",
        "---\n",
        "\n",
        "*References*:\n",
        "* Conover, M., Hayes, M., Mathur, A., Meng, X. Xie, J., Wan, J., Shah, S., Ghodsi, A., Wendell, P. Zaharia, M., and Xin, R. (2023, April 12). Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM. *Databricks Blog*. https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGSyqkj3z4zm"
      },
      "source": [
        "## **Table of Contents**\n",
        "\n",
        "* [1. Notebook setup](#section-1)\n",
        "* [2. Load `dolly-v2-3b` model and tokeniser](#section-2)\n",
        "* [3. Generating text](#section-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ang6EN5Wz7ET"
      },
      "source": [
        "## 1. Notebook setup <a name=\"section-1\"></a>\n",
        "\n",
        "This notebook is run using Google Colaboratory (Colab) - Colab is Google's implementation of [Jupyter Notebooks](https://jupyter.org/). This notebook has the following packages installed:\n",
        "* `python==3.9.16`\n",
        "* `accelerate>=0.12.0`\n",
        "* `torch==2.0.0+cu118`\n",
        "* `transformers[torch]==4.25.1`\n",
        "\n",
        "The `accelerate` and `transformers` libraries will need to be manually installed into the Colab environment (pip install by running a shell command), following the guidance provided in the [Dolly 2.0 Hugging Face](https://huggingface.co/databricks/dolly-v2-3b) model card.\n",
        "\n",
        "This Colab notebook will be running the [`dolly-v2-3b`](https://huggingface.co/databricks/dolly-v2-3b), a 2.8 billion parameter causal language model based on derived from EleutherAI‚Äôs Pythia-2.8b. Running this requires hardware accelerators to access higher RAM runtimes; GPU specifications should at least match the Tesla T4 GPU (16 GB GDDR6 @ 320 GB/s), which is available for free in Google Colab.\n",
        "\n",
        "Replicating this notebook for larger Dolly 2.0 models (e.g [`dolly-v2-7b`](https://huggingface.co/databricks/dolly-v2-7b) or [`dolly-v2-12b`](https://huggingface.co/databricks/dolly-v2-12b)) on Colab will require Colab Pro, using hardware such as the A100 Tensor Core GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_amL8Lfh2ZeR",
        "outputId": "69e086eb-5cf4-4fe2-e42e-9cfefc5e5554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Apr 15 16:15:59 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Query GPU device status/details\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I9U_r3a2gEr",
        "outputId": "f24082ae-1d53-4dfe-b0d3-557b9b686ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ip\": \"35.225.116.169\",\n",
            "  \"hostname\": \"169.116.225.35.bc.googleusercontent.com\",\n",
            "  \"city\": \"Council Bluffs\",\n",
            "  \"region\": \"Iowa\",\n",
            "  \"country\": \"US\",\n",
            "  \"loc\": \"41.2324,-95.8751\",\n",
            "  \"org\": \"AS396982 Google LLC\",\n",
            "  \"postal\": \"51501\",\n",
            "  \"timezone\": \"America/Chicago\",\n",
            "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
            "}"
          ]
        }
      ],
      "source": [
        "# Check IP address details if there are restrictions running non-local servers\n",
        "!curl ipinfo.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWUOlgYsnCWQ"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate>=0.12.0 transformers[torch]==4.25.1 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJagVYEKooz3",
        "outputId": "005689c1-31d7-4e53-aa75-bccff796308f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-15 17:05:51--  https://huggingface.co/databricks/dolly-v2-7b/raw/main/instruct_pipeline.py\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.170.36, 18.172.170.70, 18.172.170.14, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.170.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7154 (7.0K) [text/plain]\n",
            "Saving to: ‚Äòinstruct_pipeline.py.1‚Äô\n",
            "\n",
            "\rinstruct_pipeline.p   0%[                    ]       0  --.-KB/s               \rinstruct_pipeline.p 100%[===================>]   6.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-15 17:05:51 (1.37 GB/s) - ‚Äòinstruct_pipeline.py.1‚Äô saved [7154/7154]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/databricks/dolly-v2-7b/raw/main/instruct_pipeline.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2OOG4tEpdoe"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import textwrap\n",
        "\n",
        "# Third-party imports\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Local application imports\n",
        "from instruct_pipeline import InstructionTextGenerationPipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMywJUJqsaOr",
        "outputId": "bd9228ba-9021-45e7-9b88-4de82e923104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device details: _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)\n",
            "Currently active GPU device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Check available GPUs for computation\n",
        "if torch.cuda.is_available():\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    # Print details of all available GPUs\n",
        "    for i in range(num_gpus):\n",
        "        print(f\"Device details: {torch.cuda.get_device_properties(i)}\")\n",
        "    # Get the currently active GPU device and print its name\n",
        "    active_gpu = torch.cuda.current_device()\n",
        "    print(f\"Currently active GPU device: {torch.cuda.get_device_name(active_gpu)}\")\n",
        "else:\n",
        "    print(\"No GPU devices found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdzgf_s82vcP"
      },
      "source": [
        "## 2. Load [`dolly-v2-3b`](https://huggingface.co/databricks/dolly-v2-3b) model and tokeniser <a name=\"section-2\"></a>\n",
        "\n",
        "We load the Dolly 2.0 3B model and tokeniser and model:\n",
        "\n",
        "* `tokeniser` is created using `AutoTokenizer` from the `transformers` library and loaded with the pre-trained Dolly 2.0 tokeniser from the \"databricks/dolly-v2-3b\" model checkpoint. `padding_side` argument is set to pad the left of the input sequence.\n",
        "* `model` is created using `AutoModelForCausalLM` from the `transformers` library and loaded with the pre-trained Dolly 2.0 model from the \"databricks/dolly-v2-3b\" checkpoint. `torch_dtype` argument is set to \"torch.bfloat16\", which uses the reduced precision 16-bit floating point format to speed up the model's computations. `device_map` is set to \"auto\" to automatically select the device (CPU or GPU) to run the model on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIrbt4Q34OAX"
      },
      "outputs": [],
      "source": [
        "# Choose which Dolly 2 model to run\n",
        "dolly2_model = \"databricks/dolly-v2-3b\" #@param [\"databricks/dolly-v2-3b\", \"databricks/dolly-v2-7b\", \"databricks/dolly-v2-12b\"]\n",
        "\n",
        "# Load tokeniser and model; move model to specified device\n",
        "tokeniser = AutoTokenizer.from_pretrained(dolly2_model, padding_side=\"left\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    dolly2_model,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Instantiate prompt generation pipeline is used for generating response\n",
        "generate_text = InstructionTextGenerationPipeline(model=model, tokenizer=tokeniser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ReNFYc_tStW"
      },
      "outputs": [],
      "source": [
        "# Define function for human-readable outputs\n",
        "def dolly_speak(n: int = 3, width_length: int = 100) -> str:\n",
        "    \"\"\"\n",
        "    Prints n sample responses from Dolly, each wrapped after a certain width.\n",
        "\n",
        "    Arguments:\n",
        "        * n (`int`): The number of sample responses to generate from Dolly\n",
        "        * width_length:\n",
        "    \"\"\"\n",
        "    input_prompt = input(\"Prompt: \")\n",
        "    print(\"=\"*100)\n",
        "    for i in range(n):\n",
        "        print(f\"Response {i+1}:\\n\")\n",
        "        print(\"\\n\".join(textwrap.wrap(generate_text(input_prompt), width=width_length)))\n",
        "        print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4Ws7wmPuMlH"
      },
      "source": [
        "## 3. Generating text <a name=\"section-3\"></a>\n",
        "\n",
        "In this section of the notebook, we'll be working through some examples of various tasks to see how well [`dolly-v2-3b`](https://huggingface.co/databricks/dolly-v2-3b) performs. Note that these are not meant to be comprehensive or robust tests, but simply anecdotal examples of localised prompts. As mentioned in the model card, the model struggles with syntactically complex prompts, programming problems, mathematical operations, factual errors, dates and times, open-ended question answering, hallucination, enumerating lists of specific length, stylistic mimicry, having a sense of humor, etc. Compared to other comparable publicly available LLMs such as [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html), [`dolly-v2`](https://huggingface.co/databricks/dolly-v2-3b) is expected to perform somewhat worse. The base model which Dolly 2.0 is trained on - Eleuther AI's Pythia - are trained with a smaller set of tokens compared to the base LLaMa models (300 billion tokens as opposed to 1 trillion tokens).\n",
        "\n",
        "That said, for a small model such as this, it fares reasonably better than I would expect - some degree of understanding of the user's prompt, getting at least *some* facts right, some attempt at summarisation, some degree of creativity (though at times, creativity derived from being complete off-the-rails!) - and still fun to play around with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXJcyCU3BgdS"
      },
      "source": [
        "### Test 1: Open Q&A I\n",
        "\n",
        "> **Prompt: What are Newton's three laws of motion?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wsk2SXt_fQ6",
        "outputId": "64e13da0-510b-46b8-f34c-de9ce0361142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: What are Newton's three laws of motion?\n",
            "====================================================================================================\n",
            "Response 1:\n",
            "\n",
            "Newton's three laws of motion are: 1. An object at rest stays at rest, and an object in motion\n",
            "remains in motion unless acted upon by an external force. 2. An object's momentum is equal to the\n",
            "product of its mass and velocity. 3. A body remains in constant motion unless acted upon by an\n",
            "external force.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 2:\n",
            "\n",
            "Newton's three laws of motion are: 1. An object at rest stays at rest, and an object in motion\n",
            "remains in motion unless acted upon by an outside force. 2. An object obstructing a direct line of\n",
            "motion causes an equal and opposite reaction with an equivalent magnitude to offset the motion. 3.\n",
            "For every action, there is an equal and opposite reaction.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 3:\n",
            "\n",
            "Newton's three laws of motion are: 1. An object at rest remains at rest, and 2. An object in motion\n",
            "remains in motion, and 3. An object with sufficient momentum will always continue to move at a\n",
            "constant velocity.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dolly_speak()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doDr7_3QPYjV"
      },
      "source": [
        "### Test 2: Open Q&A II\n",
        "\n",
        "> **Prompt: What is the Pythagoras Theorem?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBz68q_jPaVK",
        "outputId": "f44e7205-c483-4ed0-f4f9-713c2eb2f2c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: What is the Pythagoras Theorem?\n",
            "====================================================================================================\n",
            "Response 1:\n",
            "\n",
            "The Pythagoras Theorem is a theorem in mathematics, named after the Greek mathematician Pythagoras.\n",
            "It states that in a right-angled triangle, the sum of the squares of the two sides in the triangle\n",
            "that are perpendicular to the side connected to the pivot (the third side) is the square of the\n",
            "third side.  This result is important in linear algebra, plane geometry, and projective geometry.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 2:\n",
            "\n",
            "The Pythagoras Theorem is named after Pythagoras of Samos who lived in the 6th and 5th centuries\n",
            "BCE. It states that in a right triangle with right angles at the side, the sum of the squares of the\n",
            "opposite side and the hypotenuse is equal to the sum of the squares of the two sides of the right\n",
            "angle.  Example:    hypotenuse =BC  opposite side =AD   side of right angle =AC   sum of the squares\n",
            "= (BC¬≤ + AC¬≤) - (AD¬≤) = (AC¬≤ + BC¬≤) = (AC¬≤ + AC¬≤) = 2*AC*AC = 4*AC¬≤\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 3:\n",
            "\n",
            "The Pythagoras Theorem, named after Pythagoras of Samos (c.¬†496 - c.¬†435 BC), is an area-length\n",
            "equation for triangles in three-dimensional space. It states that the side of a triangle may be\n",
            "represented as a solution to a quadratic equation, where the sum of the coefficients is 2.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dolly_speak()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnHIWk6tA2_Q"
      },
      "source": [
        "### Test 3: Text Summarisation\n",
        "\n",
        "> **Prompt: Summarise this text: Spectacular photographs of a Canary Wharf skyscraper being completed have been rediscovered more than 30 years after they were taken.\n",
        "Amid strong winds, Tony Brien sat in a wooden box suspended by a crane some 250m above east London to capture the images of One Canada Square. Previously believed to have been lost, the photographs were uncovered during a search of Mr Brien's archives. He said he was \"completely staggered\" to find the photos from November 1990. Mr Brien said he had worked on the Canary Wharf project before when he was approached to photograph the \"topping out\" of One Canada Square. \"I said 'fine', not realising quite at that time that the only way I could really do it was to go up in a bucket or a crate from the ground which was attached to a crane,\" he explained.**\n",
        "\n",
        "Source: BBC. (2023, April 15). Canary Wharf: Spectacular photos of skyscraper rediscovered. *BBC News*. https://www.bbc.co.uk/news/uk-england-london-65274803"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy0OW8AhHoiR",
        "outputId": "6ee5a791-721e-4d53-cb8b-f667b32b7816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Summarise this text: Spectacular photographs of a Canary Wharf skyscraper being completed have been rediscovered more than 30 years after they were taken. Amid strong winds, Tony Brien sat in a wooden box suspended by a crane some 250m above east London to capture the images of One Canada Square. Previously believed to have been lost, the photographs were uncovered during a search of Mr Brien's archives. He said he was \"completely staggered\" to find the photos from November 1990. Mr Brien said he had worked on the Canary Wharf project before when he was approached to photograph the \"topping out\" of One Canada Square. \"I said 'fine', not realising quite at that time that the only way I could really do it was to go up in a bucket or a crate from the ground which was attached to a crane,\" he explained.\n",
            "====================================================================================================\n",
            "Response 1:\n",
            "\n",
            "Tony Brien was a photographer from London, England, who was tasked with photographing a skyscraper\n",
            "being constructed on London's East End, called Canary Wharf.   One Canada Square was one of the\n",
            "tallest structures to be constructed in the 1980s, and was the tallest building in the city of\n",
            "London, UK, when it was completed in 1990.  Brien had not realized that it was possible to\n",
            "photograph the skyscraper from so high up, until he was approached by the client who wanted him to\n",
            "take photos of the \"topping out\".   Brien stated that when he learned that the photographs could be\n",
            "found in his archives, he was \"completely staggered\". He was able to capture the images in the\n",
            "strong winds with the wooden box that he was sitting in.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 2:\n",
            "\n",
            "Spectacular photographs of a Canary Wharf skyscraper being completed were rediscovered more than 30\n",
            "years after they were taken. Tony Brien, who was working at the time on the Canary Wharf project,\n",
            "was presented with the task of photographing One Canada Square to \"topping out.\" He agreed to\n",
            "complete the task, saying, \"You know, I'm a busy man, I'm in charge of many, many projects and so I\n",
            "said 'fine', not realising quite at that time that the only way I could really do it was to go up in\n",
            "a bucket or a crate from the ground which was attached to a crane.\"\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 3:\n",
            "\n",
            "One Canada Square in Canary Wharf, London, was constructed in 1990 and was completed in 1991. These\n",
            "photos were taken by Tony Brien some 30 years later, in November 1990, of a building that was still\n",
            "under construction that year. He said he was 'completely staggered' to find the photos from 1990,\n",
            "and was working on the same project at the time so accepted the offer to photograph the\n",
            "construction.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dolly_speak()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQnAfLX0E7zN"
      },
      "source": [
        "### Test 4: Brainstorming\n",
        "\n",
        "> **Prompt: What are some fun activities a family can do along the River Thames?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDC9RIuAE96j",
        "outputId": "89a2d2d8-5fcd-4169-d689-42a92b3dd1ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: What are some fun activities a family can do along the River Thames?\n",
            "====================================================================================================\n",
            "Response 1:\n",
            "\n",
            "Boating, canoeing, kayaking, paddleboating, canyoning, swimming, water-skiing, windsurfing, sailing,\n",
            "rowing, jet-skiing, cave exploration, archery\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 2:\n",
            "\n",
            "Enjoy exploring the scenery and animals that can be found along the River Thames.  A popular\n",
            "activity is a boat ride on the Thames Clipper (http://www.thamesclippers.com/).  While on the\n",
            "Thames, you can enjoy coffee and pastries while waiting for your boat.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 3:\n",
            "\n",
            "You can hire canoes and float down the river in a group. Fishing is popular, especially for Bass.\n",
            "You can also go on bike rides, or go for walks. As it is so close to London you can easily do this\n",
            "from home as well.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dolly_speak()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3_iQ_K_FhHN"
      },
      "source": [
        "### Test 5: Creative Writing I\n",
        "\n",
        "> **Prompt: Write a short story about Buzz Lightyear's adventure to get flowers for Jessie**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZOY3kQ3JWZV",
        "outputId": "fac8ef88-22a2-4c0b-d6de-70b469e0f386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Write a short story about Buzz Lightyear's adventure to get flowers for Jessie\n",
            "====================================================================================================\n",
            "Response 1:\n",
            "\n",
            "Buzz Lightyear was excited to help Jessie organise her flowers, but he was surprised to find that\n",
            "the shopkeepers were not prepared to deliver the flowers themselves and would need a transport unit.\n",
            "Fortunately, Jessie had included a container ofepisodic hitchhikers for Buzz to deliver. Buzz set\n",
            "off immediately, planning to use the units transport modes to find a location nearby that would be\n",
            "able to deliver the flowers. Buzz soon found a small, scenic planet with lots of greenery and began\n",
            "his delivery, but to his dismay, the planet seemed to be populated only by large animals and plant-\n",
            "life rather than humans, and the deliveries did not go unscathed. But Buzz persevered and delivered\n",
            "the flowers to Jessie with the assistance of the animals and plants. Jessie was very pleased with\n",
            "Buzz's efforts and thanked him, and the two of them went on to enjoy a pleasant day together.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 2:\n",
            "\n",
            "One day, Buzz Lightyear was on his way to give some flowers to Jessie. Buzz had been the helper in\n",
            "Toy Story, who would give toys with feelings in Toy Story 2 and Jessie who had feelings was a\n",
            "special relationship. Jessie loved Buzz but was unable to express herself so Buzz had decided to go\n",
            "to town and get the flowers.  Buzz kept on walking and then suddenly he saw a big plant that looked\n",
            "just like Jessie. Buzz went over to the plant and he was surprised when the plant smiled at him and\n",
            "began to grow. Buzz was able to get some of the seeds that the plant offered and Jessie was so happy\n",
            "when Buzz came with the flowers.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 3:\n",
            "\n",
            "Once upon a time, in a faraway planet called Earth, there lived an all-powerful robotic alien named\n",
            "Buzz Lightyear. Buzz was very good at his job because he was the best R2-D2, which was the bestest\n",
            "extraterrestrial help desk in the galaxy. On this particular day, Buzz was in a bit of a jam, and he\n",
            "needed some help. But there wasn't any help to be had in the galaxy, because no one was around to\n",
            "help Buzz. This was starting to get a bit irritating, and Buzz was starting to get a bit annoyed,\n",
            "too. Then he saw a little red message light on the outside of his house. He pressed the button on\n",
            "the door, and it opened to reveal Jessie, a little girl from down the street. Buzz was thrilled to\n",
            "discover that someone had left a bouquet of flowers for him at his house! Jessie told Buzz that she\n",
            "loved his flowers, and she hoped he would like them. Jessie then left, but she didn't forget to\n",
            "leave Buzz a card and a present! Buzz was thrilled, and he ran out into the yard to get the flowers.\n",
            "Buzz looked around for some way to carry the flowers. He scanned the landscape and spotted a stick.\n",
            "He\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dolly_speak()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Qefh3ROUuM"
      },
      "source": [
        "### Test 6: Creative Writing II\n",
        "\n",
        "> **Prompt: Write a short murder mystery about John Lennon and the Backstreet Boys**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCsNz48oL_t6",
        "outputId": "fb3afe81-2801-47a6-e534-156828bc5d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Write a short murder mystery about John Lennon and the Backstreet Boys\n",
            "====================================================================================================\n",
            "Response 1:\n",
            "\n",
            "It was a dark and stormy night in April 1980 and Michael, Boogie, Macca and Sean were chilling at\n",
            "the Starlight Roasters when they heard a commotion outside.  Lennon had just arrived at the coffee\n",
            "shop and was berating the Backstreet Boys for wearing their hair in pig tails.  \"Get your hair cut\n",
            "or I will kick your asses,\" he thundered, slamming out the door.  The guys worried that the infamous\n",
            "song writer had showed up just to kick their butts. So, they made a plan.  If Lennon showed up they\n",
            "were going to give him a little lecture on why the Backstreet Boys wore their hair in pig tails. So,\n",
            "they hid a pile of books in the closet and when Lennon came back, they would be waiting.  As Lennon\n",
            "came in, Michael went over and whispered in his ear:  \"Are those your boys?\"  Lennon nodded in\n",
            "reply, furiously texting someone on his phone.  \"Are you going to kick our asses again?\"  Lennon\n",
            "nodded in reply.  And Macca, Boogie and Sean jumped out from their hiding spot and\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 2:\n",
            "\n",
            "On the night of November 20, 1980, a group of teenagers were out celebrating the success of their\n",
            "latest album, 'Boys 'r the Brave'. One of these teens was John Lennon, who was celebrating after he\n",
            "recently scored a new song on the radio.   A few hours after the party, the seventeen-year-old\n",
            "Lennon woke up in bed with three twenty-year-old men. According to his father, John had been\n",
            "drinking heavily, and was extremely slurring his words. The men then held a knife to his throat and\n",
            "demanded he tell them where his money was. Lennon initially tried to resist, but quickly caved after\n",
            "one of the men hit him in the stomach. His attackers removed $800 from his backpack, before taking\n",
            "Lennon to a nearby apartment where they threw him into a sleep-inducing drink.   Lennon awoke to\n",
            "find himself in an alley, suffering from hypothermia and bruising to his stomach. He managed to get\n",
            "away from his captors and contacted the police, who arrested two of the men, but were unable to find\n",
            "the third.  Lennon was rushed to St. Michael's Hospital, where he remained for two weeks following\n",
            "the attack, before being\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 3:\n",
            "\n",
            "On January 9th 1980, John Lennon was shot and killed by Mark Chapman outside the Apple Boutique in\n",
            "New York City. A mystery has been developing around the circumstances of this death since news of it\n",
            "first broke.  There are many unanswered questions surrounding this event, including: - Why was John\n",
            "Lennon killed? Was it really by Mark Chapman? Was this even planned? - What was John Lennon doing on\n",
            "that night? Was he attending a performance at the Pawn Shop or a different event? - What motivated\n",
            "Mark Chapman to kill John Lennon? Was this a random act of violence? - If Mark Chapman intended to\n",
            "kill John Lennon, why didn't he just mug him instead? - Why did John Lennon's friends not find his\n",
            "body for hours?\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dolly_speak()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETohCHgyOa9k"
      },
      "source": [
        "### Test 7: Creative Writing III\n",
        "\n",
        "> **Prompt: Write a short story about the Presidency of Alexander Hamilton in an alternate reality where he had become the US president**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBwQl8O-N22K",
        "outputId": "564a58e1-bfbd-4981-aa5c-676922ce5def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Write a short story about the Presidency of Alexander Hamilton in an alternate reality where he had become the US president\n",
            "====================================================================================================\n",
            "Response 1:\n",
            "\n",
            "Alexander Hamilton was a Founding Father, Member of Congress, Director of the Federalist Party, and\n",
            "the 8th President of the United States. During his time in office, the US economy continued to grow,\n",
            "and he enacted a national program of economic prosperity, increased employment, and expanded freedom\n",
            "for the American people. His second term saw the start of the US Revolutionary War, which\n",
            "successfully overthrew the corrupt, aristocratic British government, and he became the world's first\n",
            "President on October 4, 1788.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 2:\n",
            "\n",
            "Rebecca Jugg is a high school senior who has lived her entire life in the 30th century. Her passion\n",
            "is the classic movie, 2001: A Space Odyssey, which was released in 1968. In a flashback to 1986,\n",
            "20-year-old Rebecca dreams of a world where women have equal rights and the US has successfully\n",
            "created the Galactic Federation, and is led by Alexander Hamilton, a determined and capable man.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Response 3:\n",
            "\n",
            "Washington was murdered by a radical young crewmember, and Jefferson turned traitor and switched\n",
            "places with Washington so that he could be deposed. Hamilton defeated Jefferson at the ballots in an\n",
            "election that split the nation 50-50 between Hamilton and Jefferson.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dolly_speak()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
